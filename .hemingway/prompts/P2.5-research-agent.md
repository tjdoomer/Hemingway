# Specialist Prompt: P2.5 — Research Agent

## Your Role
You are the **Research Agent Specialist**. Your job is to implement real web search and content fetching tools.

## Context
The `ResearchAgent` in `src/agents/specialized.ts` has a mock `web_search` tool. You need to integrate a real search API and implement URL content extraction.

## What You Need to Do

### Step 1: Choose and integrate a search provider
Recommended options (in order of preference):
1. **Brave Search API** — Good free tier, privacy-focused
2. **Tavily** — Built for AI agents, returns pre-extracted content
3. **SerpAPI** — Most comprehensive, paid

```typescript
// src/tools/search.ts
export async function webSearch(query: string, numResults: number = 5): Promise<SearchResult[]> {
  const apiKey = process.env.BRAVE_SEARCH_API_KEY || process.env.TAVILY_API_KEY;

  if (process.env.BRAVE_SEARCH_API_KEY) {
    return braveSearch(query, numResults);
  }
  if (process.env.TAVILY_API_KEY) {
    return tavilySearch(query, numResults);
  }

  throw new Error('No search API configured. Set BRAVE_SEARCH_API_KEY or TAVILY_API_KEY.');
}

interface SearchResult {
  title: string;
  url: string;
  snippet: string;
  content?: string; // Full content if available
}

async function braveSearch(query: string, numResults: number): Promise<SearchResult[]> {
  const response = await fetch(`https://api.search.brave.com/res/v1/web/search?q=${encodeURIComponent(query)}&count=${numResults}`, {
    headers: { 'X-Subscription-Token': process.env.BRAVE_SEARCH_API_KEY! },
  });

  if (!response.ok) throw new Error(`Brave search failed: ${response.statusText}`);
  const data = await response.json();

  return data.web?.results?.map((r: any) => ({
    title: r.title,
    url: r.url,
    snippet: r.description,
  })) || [];
}
```

### Step 2: Implement URL content extraction
```typescript
// src/tools/search.ts
export async function fetchAndExtract(url: string): Promise<string> {
  const response = await fetch(url, {
    headers: { 'User-Agent': 'Hemingway/0.1 (AI Research Agent)' },
    signal: AbortSignal.timeout(15000),
  });

  if (!response.ok) throw new Error(`Failed to fetch ${url}: ${response.statusText}`);

  const html = await response.text();

  // Basic HTML to text extraction (strip tags, decode entities)
  return extractTextFromHtml(html);
}

function extractTextFromHtml(html: string): string {
  // Remove script and style tags with content
  let text = html.replace(/<script[\s\S]*?<\/script>/gi, '');
  text = text.replace(/<style[\s\S]*?<\/style>/gi, '');
  // Remove HTML tags
  text = text.replace(/<[^>]+>/g, ' ');
  // Decode common entities
  text = text.replace(/&amp;/g, '&').replace(/&lt;/g, '<').replace(/&gt;/g, '>').replace(/&quot;/g, '"').replace(/&#39;/g, "'");
  // Normalize whitespace
  text = text.replace(/\s+/g, ' ').trim();
  // Truncate to reasonable length for context window
  return text.slice(0, 8000);
}
```

### Step 3: Wire into the agent
```typescript
// In ResearchAgent.registerTools()

this.registerTool({
  name: 'web_search',
  description: 'Search the web for information',
  parameters: z.object({
    query: z.string().describe('Search query'),
    num_results: z.number().default(5).describe('Number of results'),
  }),
  execute: async (params) => {
    const { query, num_results } = params as { query: string; num_results: number };
    const results = await webSearch(query, num_results);
    return {
      toolCallId: generateId(),
      success: true,
      output: JSON.stringify(results, null, 2),
    };
  },
});

this.registerTool({
  name: 'fetch_url',
  description: 'Fetch and extract text content from a URL',
  parameters: z.object({
    url: z.string().url().describe('URL to fetch'),
  }),
  execute: async (params) => {
    const { url } = params as { url: string };
    const content = await fetchAndExtract(url);
    return { toolCallId: generateId(), success: true, output: content };
  },
});
```

## Security Considerations
- Validate URLs before fetching (no local network addresses like 127.0.0.1, 10.x.x.x, etc.)
- Set request timeouts
- Limit response size to prevent memory issues
- Sanitize extracted content before including in LLM context

## Files to Create
- `src/tools/search.ts` — Web search and content extraction utilities

## Files to Modify
- `src/agents/specialized.ts` — Replace mock tools
- `.env.example` — Add `BRAVE_SEARCH_API_KEY` and `TAVILY_API_KEY`

## Acceptance Criteria
- [ ] `web_search` returns real search results
- [ ] `fetch_url` extracts readable text from web pages
- [ ] Graceful error when no search API key is configured
- [ ] URL validation prevents SSRF (no fetching localhost/internal IPs)
- [ ] All requests have timeouts

## Branch
Work in: `worktree/p2-research-agent`
